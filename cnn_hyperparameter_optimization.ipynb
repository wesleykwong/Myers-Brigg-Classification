{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mpu.ml\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures that tweet and user ids do not appear in scientific notation\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../NLP_MBTI_Classification/twisty_train.csv', index_col=0)\n",
    "test = pd.read_csv('../NLP_MBTI_Classification/twisty_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_num_encoding = {\n",
    "    'ISTJ':0, 'ISFJ':1, 'INFJ':2, 'INTJ':3,\n",
    "    'ISTP':4, 'ISFP':5, 'INFP':6, 'INTP':7,\n",
    "    'ESTP':8, 'ESFP':9, 'ENFP':10, 'ENTP':11,\n",
    "    'ESTJ':12, 'ESFJ':13, 'ENFJ':14, 'ENTJ':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mbti_encoding'] = train['mbti'].apply(lambda x: mbti_num_encoding[x])\n",
    "test['mbti_encoding'] = test['mbti'].apply(lambda x: mbti_num_encoding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_text</th>\n",
       "      <th>mbti_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14222</th>\n",
       "      <td>@alicedeee Ich könnte der stundenlang zuhören!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14668</th>\n",
       "      <td>@Moaxi @KatrinaJulie kann ich immer noch sehen...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>@GerhardMaier fand ich auch damals. Klappt das...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>38 qm für 700 warm ... ich muss verrückt sein ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>@dilettiert Willkommen in unserer Welt. Liebe ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13586</th>\n",
       "      <td>accorsi la deve smettere</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>io vado col finale\\nlo faccio\\nchiudo alle 4 m...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>L'evoluzione dell'Universo in una simulazione ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>E dopo essermi addormentata fra le tue braccia...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>Uscire sta diventando imbarazzante: ho chiazze...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            twitter_text  mbti_encoding\n",
       "14222  @alicedeee Ich könnte der stundenlang zuhören!...              1\n",
       "14668  @Moaxi @KatrinaJulie kann ich immer noch sehen...             10\n",
       "889    @GerhardMaier fand ich auch damals. Klappt das...             14\n",
       "7705   38 qm für 700 warm ... ich muss verrückt sein ...             10\n",
       "1585   @dilettiert Willkommen in unserer Welt. Liebe ...              7\n",
       "...                                                  ...            ...\n",
       "13586                           accorsi la deve smettere              7\n",
       "8513   io vado col finale\\nlo faccio\\nchiudo alle 4 m...              6\n",
       "1371   L'evoluzione dell'Universo in una simulazione ...             15\n",
       "4695   E dopo essermi addormentata fra le tue braccia...             13\n",
       "1551   Uscire sta diventando imbarazzante: ho chiazze...              6\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['twitter_text', 'mbti_encoding']]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitter_text</th>\n",
       "      <th>mbti_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8856</th>\n",
       "      <td>Wisst ihr was das beste an #ibes ist? Dass sie...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15218</th>\n",
       "      <td>Ich hab Connis 7 Minuten letztes Jahr auch geh...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>@fat_jacK47 ja, aber ich wärs nich :D</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>@Wally44 danke. Ist runtergeladen :)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>@Patienti_A Schlaf gut</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13638</th>\n",
       "      <td>quel momento in cui stai pedalando tranquillam...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18491</th>\n",
       "      <td>uomo perfetto????? FA SCHIFOOOOOOOOOOOOOOOOOOO...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>@amerutan non ti allarmare, sto accompagnando ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12934</th>\n",
       "      <td>- insegnarle l'italiano e avevo tipo otto anni...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>@bisc_otti anche l'anno scorso non l'ho fatta ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            twitter_text  mbti_encoding\n",
       "8856   Wisst ihr was das beste an #ibes ist? Dass sie...             11\n",
       "15218  Ich hab Connis 7 Minuten letztes Jahr auch geh...             10\n",
       "3635               @fat_jacK47 ja, aber ich wärs nich :D             10\n",
       "1065                @Wally44 danke. Ist runtergeladen :)             12\n",
       "1588                              @Patienti_A Schlaf gut              4\n",
       "...                                                  ...            ...\n",
       "13638  quel momento in cui stai pedalando tranquillam...             11\n",
       "18491  uomo perfetto????? FA SCHIFOOOOOOOOOOOOOOOOOOO...             13\n",
       "6374   @amerutan non ti allarmare, sto accompagnando ...              3\n",
       "12934  - insegnarle l'italiano e avevo tipo otto anni...              2\n",
       "1103   @bisc_otti anche l'anno scorso non l'ho fatta ...             15\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['twitter_text', 'mbti_encoding']]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Multilingual Word Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_limit = 50000 # Limit due to kernal memory constraint\n",
    "model1 = gensim.models.KeyedVectors.load_word2vec_format('wiki.de.align.vec', limit=max_word_limit)\n",
    "model2 = gensim.models.KeyedVectors.load_word2vec_format('wiki.es.align.vec', limit=max_word_limit)\n",
    "model3 = gensim.models.KeyedVectors.load_word2vec_format('wiki.it.align.vec', limit=max_word_limit)\n",
    "model4 = gensim.models.KeyedVectors.load_word2vec_format('wiki.nl.align.vec', limit=max_word_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordvec_embedding_matrix(model):\n",
    "    # initialize embedding matrix and word-to-id map:\n",
    "    embedding_matrix = np.zeros((max_word_limit + 1, 300))       \n",
    "    vocab_dict = {}\n",
    "\n",
    "    # build the embedding matrix and the word-to-id map:\n",
    "    for i, word in enumerate(model.vocab.keys()):\n",
    "        embedding_vector = model[word]\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            vocab_dict[word] = i\n",
    "    \n",
    "    return (embedding_matrix, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "em1, vd1 = wordvec_embedding_matrix(model1)\n",
    "em2, vd2 = wordvec_embedding_matrix(model2)\n",
    "em3, vd3 = wordvec_embedding_matrix(model3)\n",
    "em4, vd4 = wordvec_embedding_matrix(model4)\n",
    "\n",
    "embedding_matrix = np.vstack([em1, em2, em3, em4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {**vd1, **vd2, **vd3, **vd4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into twitter text and mbti number encoding\n",
    "X_train = train['twitter_text']\n",
    "y_train = train['mbti_encoding']\n",
    "\n",
    "X_test = test['twitter_text']\n",
    "y_test = test['mbti_encoding']\n",
    "\n",
    "# Convert number encoding to one hot vector\n",
    "#import mpu.ml\n",
    "y_train = np.array(mpu.ml.indices2one_hot(y_train, nb_classes=16))\n",
    "y_test = np.array(mpu.ml.indices2one_hot(y_test, nb_classes=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token length: 52\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "# Due to computational limitations, MAX_SEQUENCE_LENGTH has already been precalculated\n",
    "MAX_SEQUENCE_LENGTH = 52\n",
    "print(\"Max token length:\", MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_to_ids(sentences):\n",
    "    \"\"\"\n",
    "    converting a list of strings to a list of lists of word ids\n",
    "    \"\"\"\n",
    "    max_length = MAX_SEQUENCE_LENGTH\n",
    "    text_ids = np.zeros((1, max_length), dtype=int)\n",
    "    for sentence in sentences:\n",
    "        example = []\n",
    "        for word in tokenizer.tokenize(sentence):\n",
    "            if word in vocab_dict.keys():\n",
    "                example.append(vocab_dict[word])\n",
    "            #else:\n",
    "            #    example.append(0)\n",
    "\n",
    "        example = np.pad(example, (0, max_length-len(example)))\n",
    "        text_ids = np.vstack((text_ids, example))\n",
    "    \n",
    "    text_ids = np.delete(text_ids, 0, axis=0)\n",
    "\n",
    "    return text_ids\n",
    "\n",
    "X_train = sents_to_ids(X_train)\n",
    "X_test = sents_to_ids(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "weights_array = compute_class_weight('balanced', \n",
    "                       classes=np.arange(16), \n",
    "                       y=np.argmax(y_train, axis=1))\n",
    "weights = dict(zip(np.arange(16), weights_array))\n",
    "\n",
    "def cnn_model(optimizer='adam', epochs_input=30, batch_size_input=32, under_represented_weighting=False):\n",
    "    \n",
    "    # CNN Model Architecture\n",
    "    tf_model = tf.keras.Sequential()\n",
    "    tf_model.add(embedding_layer)\n",
    "    tf_model.add(tf.keras.layers.Conv1D(\n",
    "                filters=10, \n",
    "                kernel_size=3, \n",
    "                strides=1, \n",
    "                padding='same', \n",
    "                activation='relu', \n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform', \n",
    "                bias_initializer='zeros')) \n",
    "    tf_model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "    tf_model.add(Dense(100, activation='relu'))\n",
    "    tf_model.add(Dense(16, activation='sigmoid'))\n",
    "    \n",
    "    tf_model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    \n",
    "    if under_represented_weighting != False:\n",
    "        # Class weight helps to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "        # Reduces training accuracy but prevents model just predicting the most popular mbti classification\n",
    "        # Average accuracy (5th mbti metric below) stays constant with or without the weighting\n",
    "\n",
    "        #from sklearn.utils.class_weight import compute_class_weight\n",
    "        #weights_array = compute_class_weight('balanced', \n",
    "        #                       classes=np.arange(16), \n",
    "        #                       y=np.argmax(y_train, axis=1))\n",
    "        #weights = dict(zip(np.arange(16), weights_array))\n",
    "        tf_model.fit(X_train, y_train, \n",
    "                           validation_data=(X_test, y_test), \n",
    "                           class_weight=under_represented_weighting,\n",
    "                           epochs=epochs_input, \n",
    "                           batch_size=batch_size_input)\n",
    "        \n",
    "    else:\n",
    "        tf_model.fit(X_train, y_train, \n",
    "                           validation_data=(X_test, y_test), \n",
    "                           epochs=epochs_input, \n",
    "                           batch_size=batch_size_input)\n",
    "        \n",
    "    return tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbti_accuracy(y_true, y_pred):\n",
    "    # Measures accuracy for mbti classification across 5 accuracy metrics:\n",
    "    # one match, two matches, three matches, perfect match, average match\n",
    "    \n",
    "    # Average match is number of letters match / 4\n",
    "    \n",
    "    # Comparing 'ENFJ' as the true class and 'ENFP' as the predicted class,\n",
    "    # this function returns...\n",
    "    # [1, 1, 1, 0, 0.75]\n",
    "     \n",
    "    # Get index from one hot encoding of y_true\n",
    "    # Get index of highest softmax/probability output in y_pred\n",
    "    y_true_index = np.argmax(y_true, axis=1)\n",
    "    y_pred_index = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Use the index to identify the corresponding mbti class\n",
    "    mbti_num_encoding_list = list(mbti_num_encoding)\n",
    "    y_true_mbti = [mbti_num_encoding_list[idx] for idx in y_true_index]\n",
    "    y_pred_mbti = [mbti_num_encoding_list[idx] for idx in y_pred_index]\n",
    "    \n",
    "    one_match = []\n",
    "    two_matches = []\n",
    "    three_matches = []\n",
    "    perfect_match = []\n",
    "    \n",
    "    # Perform mbti accuracy measurements\n",
    "    sum_num_matches = 0\n",
    "    for i in np.arange(len(y_true_mbti)):\n",
    "        num_letter_matches = len(set(y_true_mbti[i]) & set(y_pred_mbti[i]))\n",
    "        \n",
    "        # At least 1 letter match\n",
    "        if num_letter_matches == 1:\n",
    "            one_match += [True]\n",
    "            two_matches += [False]\n",
    "            three_matches += [False]\n",
    "            perfect_match += [False]\n",
    "            \n",
    "        # At least 2 letter matches\n",
    "        elif num_letter_matches == 2:\n",
    "            one_match += [True]\n",
    "            two_matches += [True]\n",
    "            three_matches += [False]\n",
    "            perfect_match += [False]\n",
    "            \n",
    "        # At least 3 letter matches\n",
    "        elif num_letter_matches == 3:\n",
    "            one_match += [True]\n",
    "            two_matches += [True]\n",
    "            three_matches += [True]\n",
    "            perfect_match += [False]\n",
    "           \n",
    "        # Perfect match\n",
    "        else:\n",
    "            one_match += [True]\n",
    "            two_matches += [True]\n",
    "            three_matches += [True]\n",
    "            perfect_match += [True]\n",
    "        \n",
    "    # Average/partial matches\n",
    "        sum_num_matches += num_letter_matches\n",
    "    avg_num_matches = sum_num_matches/(len(y_true_mbti)*4)*100\n",
    "    \n",
    "    return np.round([np.mean(one_match)*100, \n",
    "                     np.mean(two_matches)*100, \n",
    "                     np.mean(three_matches)*100, \n",
    "                     np.mean(perfect_match)*100, \n",
    "                     avg_num_matches], \n",
    "                    2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30, 128],\n",
       "       [ 30, 256],\n",
       "       [ 30, 512],\n",
       "       [ 40, 128],\n",
       "       [ 40, 256],\n",
       "       [ 40, 512],\n",
       "       [ 50, 128],\n",
       "       [ 50, 256],\n",
       "       [ 50, 512]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = [30, 40, 50]\n",
    "batch = [128, 256, 512]\n",
    "\n",
    "combinations = np.array(np.meshgrid(epoch, batch)).T.reshape(-1, 2)\n",
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.7394 - accuracy: 0.1050 - val_loss: 2.7363 - val_accuracy: 0.1117\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6799 - accuracy: 0.1331 - val_loss: 2.7313 - val_accuracy: 0.1169\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6547 - accuracy: 0.1275 - val_loss: 2.6815 - val_accuracy: 0.1155\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6324 - accuracy: 0.1226 - val_loss: 2.7089 - val_accuracy: 0.1060\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6134 - accuracy: 0.1173 - val_loss: 2.7022 - val_accuracy: 0.1038\n",
      "Epoch 6/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5960 - accuracy: 0.1148 - val_loss: 2.6788 - val_accuracy: 0.1084\n",
      "Epoch 7/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5804 - accuracy: 0.1148 - val_loss: 2.6897 - val_accuracy: 0.0789\n",
      "Epoch 8/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5644 - accuracy: 0.1135 - val_loss: 2.7618 - val_accuracy: 0.0654\n",
      "Epoch 9/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5496 - accuracy: 0.1140 - val_loss: 2.7307 - val_accuracy: 0.0852\n",
      "Epoch 10/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5380 - accuracy: 0.1146 - val_loss: 2.7185 - val_accuracy: 0.0746\n",
      "Epoch 11/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5276 - accuracy: 0.1141 - val_loss: 2.7147 - val_accuracy: 0.0842\n",
      "Epoch 12/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5159 - accuracy: 0.1148 - val_loss: 2.6750 - val_accuracy: 0.0778\n",
      "Epoch 13/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5067 - accuracy: 0.1142 - val_loss: 2.7107 - val_accuracy: 0.0913\n",
      "Epoch 14/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4976 - accuracy: 0.1141 - val_loss: 2.7073 - val_accuracy: 0.0809\n",
      "Epoch 15/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4883 - accuracy: 0.1149 - val_loss: 2.7237 - val_accuracy: 0.0832\n",
      "Epoch 16/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4798 - accuracy: 0.1150 - val_loss: 2.7432 - val_accuracy: 0.0736\n",
      "Epoch 17/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4726 - accuracy: 0.1165 - val_loss: 2.7750 - val_accuracy: 0.0684\n",
      "Epoch 18/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4654 - accuracy: 0.1144 - val_loss: 2.7096 - val_accuracy: 0.0910\n",
      "Epoch 19/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4592 - accuracy: 0.1138 - val_loss: 2.7438 - val_accuracy: 0.0862\n",
      "Epoch 20/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4532 - accuracy: 0.1154 - val_loss: 2.7215 - val_accuracy: 0.0878\n",
      "Epoch 21/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4462 - accuracy: 0.1154 - val_loss: 2.8173 - val_accuracy: 0.0685\n",
      "Epoch 22/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4429 - accuracy: 0.1166 - val_loss: 2.7728 - val_accuracy: 0.0725\n",
      "Epoch 23/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4355 - accuracy: 0.1154 - val_loss: 2.7586 - val_accuracy: 0.0771\n",
      "Epoch 24/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4314 - accuracy: 0.1158 - val_loss: 2.7811 - val_accuracy: 0.0799\n",
      "Epoch 25/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4267 - accuracy: 0.1145 - val_loss: 2.7851 - val_accuracy: 0.0796\n",
      "Epoch 26/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4191 - accuracy: 0.1183 - val_loss: 2.7635 - val_accuracy: 0.0722\n",
      "Epoch 27/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4152 - accuracy: 0.1167 - val_loss: 2.7908 - val_accuracy: 0.0740\n",
      "Epoch 28/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4125 - accuracy: 0.1161 - val_loss: 2.7872 - val_accuracy: 0.0811\n",
      "Epoch 29/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4068 - accuracy: 0.1180 - val_loss: 2.8205 - val_accuracy: 0.0620\n",
      "Epoch 30/30\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4026 - accuracy: 0.1178 - val_loss: 2.8271 - val_accuracy: 0.0598\n",
      "Epoch 1/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.7434 - accuracy: 0.0898 - val_loss: 2.6889 - val_accuracy: 0.1301\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6854 - accuracy: 0.1316 - val_loss: 2.6965 - val_accuracy: 0.1265\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.6606 - accuracy: 0.1323 - val_loss: 2.7405 - val_accuracy: 0.1069\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6413 - accuracy: 0.1284 - val_loss: 2.7601 - val_accuracy: 0.0989\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6225 - accuracy: 0.1267 - val_loss: 2.6735 - val_accuracy: 0.1144\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6044 - accuracy: 0.1240 - val_loss: 2.7966 - val_accuracy: 0.0747\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5884 - accuracy: 0.1207 - val_loss: 2.7683 - val_accuracy: 0.0912\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5754 - accuracy: 0.1193 - val_loss: 2.6571 - val_accuracy: 0.1146\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5599 - accuracy: 0.1205 - val_loss: 2.6820 - val_accuracy: 0.0956\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5473 - accuracy: 0.1201 - val_loss: 2.7247 - val_accuracy: 0.0896\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5373 - accuracy: 0.1179 - val_loss: 2.6851 - val_accuracy: 0.1015\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5248 - accuracy: 0.1187 - val_loss: 2.6531 - val_accuracy: 0.1025\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5163 - accuracy: 0.1174 - val_loss: 2.7401 - val_accuracy: 0.0829\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5078 - accuracy: 0.1190 - val_loss: 2.6801 - val_accuracy: 0.1023\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4999 - accuracy: 0.1174 - val_loss: 2.7639 - val_accuracy: 0.0742\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4899 - accuracy: 0.1180 - val_loss: 2.7347 - val_accuracy: 0.0951\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4835 - accuracy: 0.1208 - val_loss: 2.7258 - val_accuracy: 0.0862\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4773 - accuracy: 0.1165 - val_loss: 2.7204 - val_accuracy: 0.0887\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4687 - accuracy: 0.1192 - val_loss: 2.7501 - val_accuracy: 0.0821\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4625 - accuracy: 0.1193 - val_loss: 2.7507 - val_accuracy: 0.0765\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4563 - accuracy: 0.1177 - val_loss: 2.7356 - val_accuracy: 0.0869\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4540 - accuracy: 0.1195 - val_loss: 2.7312 - val_accuracy: 0.0828\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4453 - accuracy: 0.1190 - val_loss: 2.7518 - val_accuracy: 0.0840\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4412 - accuracy: 0.1189 - val_loss: 2.8099 - val_accuracy: 0.0717\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4359 - accuracy: 0.1191 - val_loss: 2.7793 - val_accuracy: 0.0781\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4290 - accuracy: 0.1196 - val_loss: 2.7709 - val_accuracy: 0.0782\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4247 - accuracy: 0.1191 - val_loss: 2.7543 - val_accuracy: 0.0891\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4207 - accuracy: 0.1186 - val_loss: 2.7776 - val_accuracy: 0.0786\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4152 - accuracy: 0.1195 - val_loss: 2.7675 - val_accuracy: 0.0815\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4120 - accuracy: 0.1192 - val_loss: 2.7513 - val_accuracy: 0.0891\n",
      "Epoch 1/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.7582 - accuracy: 0.0875 - val_loss: 2.7327 - val_accuracy: 0.1157\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.7035 - accuracy: 0.1368 - val_loss: 2.7223 - val_accuracy: 0.1257\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.6845 - accuracy: 0.1417 - val_loss: 2.6912 - val_accuracy: 0.1377\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.6686 - accuracy: 0.1389 - val_loss: 2.7196 - val_accuracy: 0.1220\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.6527 - accuracy: 0.1321 - val_loss: 2.6950 - val_accuracy: 0.1296\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.6387 - accuracy: 0.1287 - val_loss: 2.6705 - val_accuracy: 0.1208\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.6274 - accuracy: 0.1256 - val_loss: 2.6571 - val_accuracy: 0.1324\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.6144 - accuracy: 0.1270 - val_loss: 2.6768 - val_accuracy: 0.1128\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.6028 - accuracy: 0.1231 - val_loss: 2.7009 - val_accuracy: 0.0996\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.5912 - accuracy: 0.1224 - val_loss: 2.6919 - val_accuracy: 0.1076\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.5813 - accuracy: 0.1209 - val_loss: 2.7266 - val_accuracy: 0.0859\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.5721 - accuracy: 0.1164 - val_loss: 2.7278 - val_accuracy: 0.0904\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.5625 - accuracy: 0.1151 - val_loss: 2.7284 - val_accuracy: 0.0898\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.5537 - accuracy: 0.1170 - val_loss: 2.7125 - val_accuracy: 0.0940\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.5446 - accuracy: 0.1146 - val_loss: 2.7003 - val_accuracy: 0.0984\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.5385 - accuracy: 0.1131 - val_loss: 2.7531 - val_accuracy: 0.0780\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.5296 - accuracy: 0.1168 - val_loss: 2.7147 - val_accuracy: 0.0911\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.5233 - accuracy: 0.1140 - val_loss: 2.7501 - val_accuracy: 0.0769\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 2.5175 - accuracy: 0.1116 - val_loss: 2.7231 - val_accuracy: 0.0838\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.5114 - accuracy: 0.1154 - val_loss: 2.7147 - val_accuracy: 0.0853\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 28s 181ms/step - loss: 2.5025 - accuracy: 0.1143 - val_loss: 2.7516 - val_accuracy: 0.0786\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.4984 - accuracy: 0.1132 - val_loss: 2.8011 - val_accuracy: 0.0668\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.4957 - accuracy: 0.1132 - val_loss: 2.7400 - val_accuracy: 0.0803\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.4862 - accuracy: 0.1136 - val_loss: 2.7248 - val_accuracy: 0.0867\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 29s 182ms/step - loss: 2.4821 - accuracy: 0.1129 - val_loss: 2.7123 - val_accuracy: 0.0873\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.4774 - accuracy: 0.1154 - val_loss: 2.7696 - val_accuracy: 0.0741\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.4738 - accuracy: 0.1122 - val_loss: 2.7643 - val_accuracy: 0.0729\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.4684 - accuracy: 0.1150 - val_loss: 2.8042 - val_accuracy: 0.0640\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.4671 - accuracy: 0.1145 - val_loss: 2.7650 - val_accuracy: 0.0774\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.4647 - accuracy: 0.1143 - val_loss: 2.8097 - val_accuracy: 0.0671\n",
      "Epoch 1/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.7271 - accuracy: 0.1135 - val_loss: 2.6871 - val_accuracy: 0.1406\n",
      "Epoch 2/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6738 - accuracy: 0.1303 - val_loss: 2.6701 - val_accuracy: 0.1385\n",
      "Epoch 3/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6503 - accuracy: 0.1274 - val_loss: 2.6669 - val_accuracy: 0.1160\n",
      "Epoch 4/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6291 - accuracy: 0.1255 - val_loss: 2.6882 - val_accuracy: 0.1199\n",
      "Epoch 5/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.6102 - accuracy: 0.1248 - val_loss: 2.6862 - val_accuracy: 0.1151\n",
      "Epoch 6/40\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.5923 - accuracy: 0.1209 - val_loss: 2.7271 - val_accuracy: 0.0829\n",
      "Epoch 7/40\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.5756 - accuracy: 0.1158 - val_loss: 2.7076 - val_accuracy: 0.0868\n",
      "Epoch 8/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5595 - accuracy: 0.1141 - val_loss: 2.6764 - val_accuracy: 0.1008\n",
      "Epoch 9/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5475 - accuracy: 0.1142 - val_loss: 2.7186 - val_accuracy: 0.0784\n",
      "Epoch 10/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5311 - accuracy: 0.1133 - val_loss: 2.7073 - val_accuracy: 0.0790\n",
      "Epoch 11/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5206 - accuracy: 0.1131 - val_loss: 2.7411 - val_accuracy: 0.0668\n",
      "Epoch 12/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.5098 - accuracy: 0.1119 - val_loss: 2.7340 - val_accuracy: 0.0790\n",
      "Epoch 13/40\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 2.4986 - accuracy: 0.1109 - val_loss: 2.7166 - val_accuracy: 0.0791\n",
      "Epoch 14/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4894 - accuracy: 0.1119 - val_loss: 2.7102 - val_accuracy: 0.0816\n",
      "Epoch 15/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4789 - accuracy: 0.1117 - val_loss: 2.7152 - val_accuracy: 0.0812\n",
      "Epoch 16/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4688 - accuracy: 0.1132 - val_loss: 2.7466 - val_accuracy: 0.0699\n",
      "Epoch 17/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4623 - accuracy: 0.1107 - val_loss: 2.7584 - val_accuracy: 0.0702\n",
      "Epoch 18/40\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.4549 - accuracy: 0.1116 - val_loss: 2.7662 - val_accuracy: 0.0685\n",
      "Epoch 19/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4469 - accuracy: 0.1122 - val_loss: 2.7799 - val_accuracy: 0.0660\n",
      "Epoch 20/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4413 - accuracy: 0.1126 - val_loss: 2.7662 - val_accuracy: 0.0707\n",
      "Epoch 21/40\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 2.4313 - accuracy: 0.1131 - val_loss: 2.7368 - val_accuracy: 0.0726\n",
      "Epoch 22/40\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.4260 - accuracy: 0.1120 - val_loss: 2.7761 - val_accuracy: 0.0643\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4215 - accuracy: 0.1118 - val_loss: 2.7458 - val_accuracy: 0.0884\n",
      "Epoch 24/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4145 - accuracy: 0.1133 - val_loss: 2.7657 - val_accuracy: 0.0692\n",
      "Epoch 25/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4094 - accuracy: 0.1130 - val_loss: 2.7831 - val_accuracy: 0.0793\n",
      "Epoch 26/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4047 - accuracy: 0.1143 - val_loss: 2.7641 - val_accuracy: 0.0828\n",
      "Epoch 27/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3978 - accuracy: 0.1145 - val_loss: 2.7765 - val_accuracy: 0.0780\n",
      "Epoch 28/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3932 - accuracy: 0.1140 - val_loss: 2.7715 - val_accuracy: 0.0759\n",
      "Epoch 29/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3885 - accuracy: 0.1168 - val_loss: 2.7888 - val_accuracy: 0.0781\n",
      "Epoch 30/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3845 - accuracy: 0.1158 - val_loss: 2.8002 - val_accuracy: 0.0697\n",
      "Epoch 31/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3798 - accuracy: 0.1152 - val_loss: 2.7760 - val_accuracy: 0.0868\n",
      "Epoch 32/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3756 - accuracy: 0.1159 - val_loss: 2.8030 - val_accuracy: 0.0707\n",
      "Epoch 33/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3726 - accuracy: 0.1159 - val_loss: 2.8133 - val_accuracy: 0.0779\n",
      "Epoch 34/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3706 - accuracy: 0.1160 - val_loss: 2.8096 - val_accuracy: 0.0758\n",
      "Epoch 35/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3633 - accuracy: 0.1157 - val_loss: 2.8141 - val_accuracy: 0.0692\n",
      "Epoch 36/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3615 - accuracy: 0.1168 - val_loss: 2.8315 - val_accuracy: 0.0701\n",
      "Epoch 37/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3561 - accuracy: 0.1170 - val_loss: 2.8336 - val_accuracy: 0.0664\n",
      "Epoch 38/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3572 - accuracy: 0.1174 - val_loss: 2.7875 - val_accuracy: 0.0869\n",
      "Epoch 39/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3495 - accuracy: 0.1192 - val_loss: 2.8584 - val_accuracy: 0.0647\n",
      "Epoch 40/40\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3464 - accuracy: 0.1181 - val_loss: 2.8393 - val_accuracy: 0.0742\n",
      "Epoch 1/40\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.7530 - accuracy: 0.1027 - val_loss: 2.7039 - val_accuracy: 0.1217\n",
      "Epoch 2/40\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6813 - accuracy: 0.1248 - val_loss: 2.6858 - val_accuracy: 0.1258\n",
      "Epoch 3/40\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6528 - accuracy: 0.1292 - val_loss: 2.7320 - val_accuracy: 0.1042\n",
      "Epoch 4/40\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.6298 - accuracy: 0.1245 - val_loss: 2.6645 - val_accuracy: 0.1208\n",
      "Epoch 5/40\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.6104 - accuracy: 0.1183 - val_loss: 2.6783 - val_accuracy: 0.1147\n",
      "Epoch 6/40\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.5927 - accuracy: 0.1157 - val_loss: 2.6833 - val_accuracy: 0.1075\n",
      "Epoch 7/40\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 2.5779 - accuracy: 0.1141 - val_loss: 2.6686 - val_accuracy: 0.1022\n",
      "Epoch 8/40\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 2.5605 - accuracy: 0.1134 - val_loss: 2.6867 - val_accuracy: 0.0835\n",
      "Epoch 9/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5481 - accuracy: 0.1097 - val_loss: 2.7251 - val_accuracy: 0.0768\n",
      "Epoch 10/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5355 - accuracy: 0.1093 - val_loss: 2.7213 - val_accuracy: 0.0856\n",
      "Epoch 11/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5214 - accuracy: 0.1109 - val_loss: 2.6994 - val_accuracy: 0.0778\n",
      "Epoch 12/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5100 - accuracy: 0.1098 - val_loss: 2.6729 - val_accuracy: 0.0886\n",
      "Epoch 13/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4998 - accuracy: 0.1115 - val_loss: 2.7377 - val_accuracy: 0.0751\n",
      "Epoch 14/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4911 - accuracy: 0.1101 - val_loss: 2.7073 - val_accuracy: 0.0785\n",
      "Epoch 15/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4825 - accuracy: 0.1114 - val_loss: 2.7586 - val_accuracy: 0.0782\n",
      "Epoch 16/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4729 - accuracy: 0.1117 - val_loss: 2.7148 - val_accuracy: 0.0807\n",
      "Epoch 17/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4651 - accuracy: 0.1117 - val_loss: 2.7945 - val_accuracy: 0.0578\n",
      "Epoch 18/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4585 - accuracy: 0.1118 - val_loss: 2.7427 - val_accuracy: 0.0676\n",
      "Epoch 19/40\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 2.4518 - accuracy: 0.1112 - val_loss: 2.6986 - val_accuracy: 0.0842\n",
      "Epoch 20/40\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.4435 - accuracy: 0.1130 - val_loss: 2.7467 - val_accuracy: 0.0719\n",
      "Epoch 21/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4359 - accuracy: 0.1132 - val_loss: 2.7264 - val_accuracy: 0.0749\n",
      "Epoch 22/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4321 - accuracy: 0.1119 - val_loss: 2.7550 - val_accuracy: 0.0743\n",
      "Epoch 23/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4246 - accuracy: 0.1128 - val_loss: 2.7377 - val_accuracy: 0.0738\n",
      "Epoch 24/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4192 - accuracy: 0.1152 - val_loss: 2.7221 - val_accuracy: 0.0798\n",
      "Epoch 25/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4133 - accuracy: 0.1130 - val_loss: 2.7498 - val_accuracy: 0.0732\n",
      "Epoch 26/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4079 - accuracy: 0.1150 - val_loss: 2.7824 - val_accuracy: 0.0674\n",
      "Epoch 27/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4023 - accuracy: 0.1151 - val_loss: 2.7766 - val_accuracy: 0.0758\n",
      "Epoch 28/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3988 - accuracy: 0.1171 - val_loss: 2.7598 - val_accuracy: 0.0748\n",
      "Epoch 29/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3944 - accuracy: 0.1154 - val_loss: 2.7842 - val_accuracy: 0.0733\n",
      "Epoch 30/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3898 - accuracy: 0.1163 - val_loss: 2.7664 - val_accuracy: 0.0739\n",
      "Epoch 31/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3847 - accuracy: 0.1160 - val_loss: 2.7875 - val_accuracy: 0.0738\n",
      "Epoch 32/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3814 - accuracy: 0.1171 - val_loss: 2.8069 - val_accuracy: 0.0683\n",
      "Epoch 33/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3771 - accuracy: 0.1174 - val_loss: 2.8287 - val_accuracy: 0.0617\n",
      "Epoch 34/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3741 - accuracy: 0.1175 - val_loss: 2.8207 - val_accuracy: 0.0686\n",
      "Epoch 35/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3690 - accuracy: 0.1184 - val_loss: 2.7841 - val_accuracy: 0.0775\n",
      "Epoch 36/40\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.3660 - accuracy: 0.1189 - val_loss: 2.8053 - val_accuracy: 0.0712\n",
      "Epoch 37/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3648 - accuracy: 0.1187 - val_loss: 2.8146 - val_accuracy: 0.0715\n",
      "Epoch 38/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3617 - accuracy: 0.1186 - val_loss: 2.8196 - val_accuracy: 0.0755\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3538 - accuracy: 0.1195 - val_loss: 2.8222 - val_accuracy: 0.0724\n",
      "Epoch 40/40\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3521 - accuracy: 0.1199 - val_loss: 2.8300 - val_accuracy: 0.0729\n",
      "Epoch 1/40\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.7636 - accuracy: 0.0927 - val_loss: 2.7311 - val_accuracy: 0.1142\n",
      "Epoch 2/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.7017 - accuracy: 0.1238 - val_loss: 2.7153 - val_accuracy: 0.1191\n",
      "Epoch 3/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.6720 - accuracy: 0.1278 - val_loss: 2.7021 - val_accuracy: 0.1182\n",
      "Epoch 4/40\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.6524 - accuracy: 0.1289 - val_loss: 2.7381 - val_accuracy: 0.1037\n",
      "Epoch 5/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.6368 - accuracy: 0.1252 - val_loss: 2.7034 - val_accuracy: 0.1077\n",
      "Epoch 6/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.6198 - accuracy: 0.1235 - val_loss: 2.7069 - val_accuracy: 0.0997\n",
      "Epoch 7/40\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.6064 - accuracy: 0.1202 - val_loss: 2.7120 - val_accuracy: 0.0972\n",
      "Epoch 8/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.5924 - accuracy: 0.1175 - val_loss: 2.6900 - val_accuracy: 0.0911\n",
      "Epoch 9/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5794 - accuracy: 0.1151 - val_loss: 2.6929 - val_accuracy: 0.1034\n",
      "Epoch 10/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5678 - accuracy: 0.1146 - val_loss: 2.6778 - val_accuracy: 0.1026\n",
      "Epoch 11/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5566 - accuracy: 0.1136 - val_loss: 2.7647 - val_accuracy: 0.0732\n",
      "Epoch 12/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5473 - accuracy: 0.1126 - val_loss: 2.6600 - val_accuracy: 0.0955\n",
      "Epoch 13/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.5367 - accuracy: 0.1138 - val_loss: 2.7073 - val_accuracy: 0.0833\n",
      "Epoch 14/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5273 - accuracy: 0.1138 - val_loss: 2.7309 - val_accuracy: 0.0727\n",
      "Epoch 15/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5172 - accuracy: 0.1132 - val_loss: 2.7076 - val_accuracy: 0.0868\n",
      "Epoch 16/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.5108 - accuracy: 0.1145 - val_loss: 2.7001 - val_accuracy: 0.0922\n",
      "Epoch 17/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5050 - accuracy: 0.1131 - val_loss: 2.7421 - val_accuracy: 0.0750\n",
      "Epoch 18/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4942 - accuracy: 0.1147 - val_loss: 2.6972 - val_accuracy: 0.0883\n",
      "Epoch 19/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4870 - accuracy: 0.1154 - val_loss: 2.7962 - val_accuracy: 0.0635\n",
      "Epoch 20/40\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.4820 - accuracy: 0.1132 - val_loss: 2.7559 - val_accuracy: 0.0794\n",
      "Epoch 21/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4741 - accuracy: 0.1165 - val_loss: 2.7275 - val_accuracy: 0.0883\n",
      "Epoch 22/40\n",
      "157/157 [==============================] - 28s 180ms/step - loss: 2.4679 - accuracy: 0.1174 - val_loss: 2.7548 - val_accuracy: 0.0795\n",
      "Epoch 23/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4642 - accuracy: 0.1169 - val_loss: 2.7454 - val_accuracy: 0.0813\n",
      "Epoch 24/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4599 - accuracy: 0.1174 - val_loss: 2.7089 - val_accuracy: 0.0705\n",
      "Epoch 25/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4521 - accuracy: 0.1167 - val_loss: 2.7470 - val_accuracy: 0.0755\n",
      "Epoch 26/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4487 - accuracy: 0.1168 - val_loss: 2.7144 - val_accuracy: 0.0882\n",
      "Epoch 27/40\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.4436 - accuracy: 0.1173 - val_loss: 2.7591 - val_accuracy: 0.0764\n",
      "Epoch 28/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4379 - accuracy: 0.1186 - val_loss: 2.7507 - val_accuracy: 0.0742\n",
      "Epoch 29/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4326 - accuracy: 0.1183 - val_loss: 2.7372 - val_accuracy: 0.0782\n",
      "Epoch 30/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4278 - accuracy: 0.1181 - val_loss: 2.7644 - val_accuracy: 0.0777\n",
      "Epoch 31/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4226 - accuracy: 0.1184 - val_loss: 2.7831 - val_accuracy: 0.0737\n",
      "Epoch 32/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4204 - accuracy: 0.1198 - val_loss: 2.7776 - val_accuracy: 0.0689\n",
      "Epoch 33/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4149 - accuracy: 0.1179 - val_loss: 2.8009 - val_accuracy: 0.0710\n",
      "Epoch 34/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4132 - accuracy: 0.1191 - val_loss: 2.7633 - val_accuracy: 0.0785\n",
      "Epoch 35/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4095 - accuracy: 0.1201 - val_loss: 2.7830 - val_accuracy: 0.0746\n",
      "Epoch 36/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4058 - accuracy: 0.1192 - val_loss: 2.7855 - val_accuracy: 0.0731\n",
      "Epoch 37/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4034 - accuracy: 0.1198 - val_loss: 2.7445 - val_accuracy: 0.0781\n",
      "Epoch 38/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3990 - accuracy: 0.1204 - val_loss: 2.7891 - val_accuracy: 0.0654\n",
      "Epoch 39/40\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3939 - accuracy: 0.1201 - val_loss: 2.7624 - val_accuracy: 0.0705\n",
      "Epoch 40/40\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.3924 - accuracy: 0.1211 - val_loss: 2.7568 - val_accuracy: 0.0768\n",
      "Epoch 1/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.7322 - accuracy: 0.1018 - val_loss: 2.7308 - val_accuracy: 0.1196\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.6753 - accuracy: 0.1294 - val_loss: 2.7365 - val_accuracy: 0.1110\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.6470 - accuracy: 0.1267 - val_loss: 2.6674 - val_accuracy: 0.1182\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.6257 - accuracy: 0.1203 - val_loss: 2.6725 - val_accuracy: 0.1152\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.6039 - accuracy: 0.1150 - val_loss: 2.6977 - val_accuracy: 0.1090\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.5842 - accuracy: 0.1112 - val_loss: 2.6847 - val_accuracy: 0.1046\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.5670 - accuracy: 0.1102 - val_loss: 2.7027 - val_accuracy: 0.0952\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.5515 - accuracy: 0.1091 - val_loss: 2.7020 - val_accuracy: 0.0890\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.5341 - accuracy: 0.1094 - val_loss: 2.7058 - val_accuracy: 0.0909\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.5201 - accuracy: 0.1114 - val_loss: 2.6941 - val_accuracy: 0.0935\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.5088 - accuracy: 0.1105 - val_loss: 2.7289 - val_accuracy: 0.0843\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4977 - accuracy: 0.1107 - val_loss: 2.7344 - val_accuracy: 0.0807\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.4861 - accuracy: 0.1117 - val_loss: 2.7068 - val_accuracy: 0.0834\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4758 - accuracy: 0.1108 - val_loss: 2.7350 - val_accuracy: 0.0810\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4659 - accuracy: 0.1125 - val_loss: 2.7471 - val_accuracy: 0.0786\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.4575 - accuracy: 0.1138 - val_loss: 2.7431 - val_accuracy: 0.0818\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4523 - accuracy: 0.1141 - val_loss: 2.7277 - val_accuracy: 0.0904\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4411 - accuracy: 0.1138 - val_loss: 2.7389 - val_accuracy: 0.0871\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4365 - accuracy: 0.1160 - val_loss: 2.7484 - val_accuracy: 0.0830\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.4271 - accuracy: 0.1153 - val_loss: 2.7474 - val_accuracy: 0.0787\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.4224 - accuracy: 0.1145 - val_loss: 2.7836 - val_accuracy: 0.0749\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4152 - accuracy: 0.1165 - val_loss: 2.7745 - val_accuracy: 0.0764\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4108 - accuracy: 0.1155 - val_loss: 2.7603 - val_accuracy: 0.0805\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.4046 - accuracy: 0.1167 - val_loss: 2.8056 - val_accuracy: 0.0644\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3994 - accuracy: 0.1166 - val_loss: 2.7728 - val_accuracy: 0.0850\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3929 - accuracy: 0.1185 - val_loss: 2.7938 - val_accuracy: 0.0785\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3884 - accuracy: 0.1182 - val_loss: 2.7897 - val_accuracy: 0.0733\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3820 - accuracy: 0.1179 - val_loss: 2.8060 - val_accuracy: 0.0685\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3774 - accuracy: 0.1190 - val_loss: 2.7936 - val_accuracy: 0.0791\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.3739 - accuracy: 0.1182 - val_loss: 2.8106 - val_accuracy: 0.0742\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 2.3714 - accuracy: 0.1199 - val_loss: 2.8151 - val_accuracy: 0.0670\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 2.3655 - accuracy: 0.1191 - val_loss: 2.7803 - val_accuracy: 0.0813\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3640 - accuracy: 0.1204 - val_loss: 2.7982 - val_accuracy: 0.0772\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3569 - accuracy: 0.1213 - val_loss: 2.8208 - val_accuracy: 0.0733\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3535 - accuracy: 0.1217 - val_loss: 2.8477 - val_accuracy: 0.0632\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3505 - accuracy: 0.1220 - val_loss: 2.8281 - val_accuracy: 0.0730\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3457 - accuracy: 0.1230 - val_loss: 2.8438 - val_accuracy: 0.0663\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3412 - accuracy: 0.1219 - val_loss: 2.8225 - val_accuracy: 0.0750\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3406 - accuracy: 0.1225 - val_loss: 2.8291 - val_accuracy: 0.0736\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3384 - accuracy: 0.1226 - val_loss: 2.8261 - val_accuracy: 0.0776\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3324 - accuracy: 0.1238 - val_loss: 2.8537 - val_accuracy: 0.0697\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3299 - accuracy: 0.1245 - val_loss: 2.8840 - val_accuracy: 0.0645\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3289 - accuracy: 0.1242 - val_loss: 2.8776 - val_accuracy: 0.0631\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3251 - accuracy: 0.1239 - val_loss: 2.8401 - val_accuracy: 0.0741\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3212 - accuracy: 0.1248 - val_loss: 2.8760 - val_accuracy: 0.0697\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3210 - accuracy: 0.1248 - val_loss: 2.8583 - val_accuracy: 0.0711\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3174 - accuracy: 0.1259 - val_loss: 2.8800 - val_accuracy: 0.0720\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3152 - accuracy: 0.1259 - val_loss: 2.8683 - val_accuracy: 0.0695\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3139 - accuracy: 0.1262 - val_loss: 2.8733 - val_accuracy: 0.0670\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.3083 - accuracy: 0.1258 - val_loss: 2.8773 - val_accuracy: 0.0732\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.7405 - accuracy: 0.1048 - val_loss: 2.6967 - val_accuracy: 0.1353\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6900 - accuracy: 0.1307 - val_loss: 2.7429 - val_accuracy: 0.1151\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6662 - accuracy: 0.1299 - val_loss: 2.7117 - val_accuracy: 0.1195\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.6464 - accuracy: 0.1278 - val_loss: 2.7042 - val_accuracy: 0.1160\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6299 - accuracy: 0.1247 - val_loss: 2.7043 - val_accuracy: 0.1120\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.6114 - accuracy: 0.1214 - val_loss: 2.7032 - val_accuracy: 0.1128\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.5960 - accuracy: 0.1204 - val_loss: 2.7178 - val_accuracy: 0.0898\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5827 - accuracy: 0.1173 - val_loss: 2.7029 - val_accuracy: 0.1022\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5654 - accuracy: 0.1150 - val_loss: 2.6891 - val_accuracy: 0.1019\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5544 - accuracy: 0.1146 - val_loss: 2.7082 - val_accuracy: 0.0912\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5443 - accuracy: 0.1130 - val_loss: 2.6777 - val_accuracy: 0.1019\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5326 - accuracy: 0.1142 - val_loss: 2.7471 - val_accuracy: 0.0759\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.5210 - accuracy: 0.1132 - val_loss: 2.6981 - val_accuracy: 0.0879\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5142 - accuracy: 0.1128 - val_loss: 2.7069 - val_accuracy: 0.0853\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.5003 - accuracy: 0.1117 - val_loss: 2.7493 - val_accuracy: 0.0782\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4936 - accuracy: 0.1117 - val_loss: 2.7659 - val_accuracy: 0.0739\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4857 - accuracy: 0.1127 - val_loss: 2.6902 - val_accuracy: 0.0938\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4777 - accuracy: 0.1125 - val_loss: 2.7371 - val_accuracy: 0.0661\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4714 - accuracy: 0.1112 - val_loss: 2.7204 - val_accuracy: 0.0845\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4647 - accuracy: 0.1125 - val_loss: 2.7300 - val_accuracy: 0.0771\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4570 - accuracy: 0.1131 - val_loss: 2.7341 - val_accuracy: 0.0759\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4528 - accuracy: 0.1130 - val_loss: 2.7712 - val_accuracy: 0.0663\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.4468 - accuracy: 0.1119 - val_loss: 2.7319 - val_accuracy: 0.0778\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4413 - accuracy: 0.1132 - val_loss: 2.7849 - val_accuracy: 0.0675\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 2.4368 - accuracy: 0.1134 - val_loss: 2.8012 - val_accuracy: 0.0578\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 2.4296 - accuracy: 0.1142 - val_loss: 2.7586 - val_accuracy: 0.0654\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4260 - accuracy: 0.1137 - val_loss: 2.7762 - val_accuracy: 0.0771\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4222 - accuracy: 0.1128 - val_loss: 2.7669 - val_accuracy: 0.0692\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4155 - accuracy: 0.1142 - val_loss: 2.8125 - val_accuracy: 0.0624\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4149 - accuracy: 0.1139 - val_loss: 2.7449 - val_accuracy: 0.0730\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4091 - accuracy: 0.1155 - val_loss: 2.7675 - val_accuracy: 0.0714\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4033 - accuracy: 0.1134 - val_loss: 2.7590 - val_accuracy: 0.0783\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.4014 - accuracy: 0.1148 - val_loss: 2.7981 - val_accuracy: 0.0774\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3981 - accuracy: 0.1151 - val_loss: 2.8255 - val_accuracy: 0.0706\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3929 - accuracy: 0.1160 - val_loss: 2.7731 - val_accuracy: 0.0684\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3869 - accuracy: 0.1153 - val_loss: 2.8084 - val_accuracy: 0.0627\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3859 - accuracy: 0.1149 - val_loss: 2.7993 - val_accuracy: 0.0680\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.3833 - accuracy: 0.1168 - val_loss: 2.7962 - val_accuracy: 0.0674\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3803 - accuracy: 0.1165 - val_loss: 2.8261 - val_accuracy: 0.0681\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3738 - accuracy: 0.1182 - val_loss: 2.7809 - val_accuracy: 0.0708\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3729 - accuracy: 0.1157 - val_loss: 2.8477 - val_accuracy: 0.0604\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3696 - accuracy: 0.1176 - val_loss: 2.7923 - val_accuracy: 0.0816\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.3674 - accuracy: 0.1170 - val_loss: 2.8138 - val_accuracy: 0.0711\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3618 - accuracy: 0.1189 - val_loss: 2.8026 - val_accuracy: 0.0700\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 29s 91ms/step - loss: 2.3636 - accuracy: 0.1172 - val_loss: 2.7966 - val_accuracy: 0.0761\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3577 - accuracy: 0.1196 - val_loss: 2.8480 - val_accuracy: 0.0647\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3562 - accuracy: 0.1186 - val_loss: 2.8022 - val_accuracy: 0.0781\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3527 - accuracy: 0.1195 - val_loss: 2.8372 - val_accuracy: 0.0697\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3507 - accuracy: 0.1193 - val_loss: 2.8110 - val_accuracy: 0.0768\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 29s 92ms/step - loss: 2.3458 - accuracy: 0.1193 - val_loss: 2.8305 - val_accuracy: 0.0742\n",
      "Epoch 1/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.7616 - accuracy: 0.0814 - val_loss: 2.7397 - val_accuracy: 0.1107\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.7023 - accuracy: 0.1208 - val_loss: 2.7213 - val_accuracy: 0.1067\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.6786 - accuracy: 0.1239 - val_loss: 2.6890 - val_accuracy: 0.1205\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.6598 - accuracy: 0.1259 - val_loss: 2.6822 - val_accuracy: 0.1218\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.6401 - accuracy: 0.1254 - val_loss: 2.7038 - val_accuracy: 0.1063\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.6228 - accuracy: 0.1205 - val_loss: 2.6983 - val_accuracy: 0.1038\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.6052 - accuracy: 0.1185 - val_loss: 2.7288 - val_accuracy: 0.0926\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5895 - accuracy: 0.1141 - val_loss: 2.6740 - val_accuracy: 0.1010\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5774 - accuracy: 0.1123 - val_loss: 2.6802 - val_accuracy: 0.0994\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5662 - accuracy: 0.1123 - val_loss: 2.6591 - val_accuracy: 0.1042\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5533 - accuracy: 0.1108 - val_loss: 2.6917 - val_accuracy: 0.0930\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5431 - accuracy: 0.1099 - val_loss: 2.6744 - val_accuracy: 0.1019\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.5335 - accuracy: 0.1101 - val_loss: 2.7036 - val_accuracy: 0.0811\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5237 - accuracy: 0.1115 - val_loss: 2.7346 - val_accuracy: 0.0697\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5179 - accuracy: 0.1098 - val_loss: 2.7859 - val_accuracy: 0.0684\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.5073 - accuracy: 0.1106 - val_loss: 2.7265 - val_accuracy: 0.0778\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.5016 - accuracy: 0.1113 - val_loss: 2.7304 - val_accuracy: 0.0755\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4943 - accuracy: 0.1103 - val_loss: 2.7182 - val_accuracy: 0.0785\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4864 - accuracy: 0.1105 - val_loss: 2.7016 - val_accuracy: 0.0873\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 28s 176ms/step - loss: 2.4814 - accuracy: 0.1109 - val_loss: 2.7662 - val_accuracy: 0.0760\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4749 - accuracy: 0.1107 - val_loss: 2.7271 - val_accuracy: 0.0835\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4681 - accuracy: 0.1116 - val_loss: 2.6907 - val_accuracy: 0.0883\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4638 - accuracy: 0.1117 - val_loss: 2.7136 - val_accuracy: 0.0816\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4586 - accuracy: 0.1128 - val_loss: 2.7334 - val_accuracy: 0.0772\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4542 - accuracy: 0.1124 - val_loss: 2.7286 - val_accuracy: 0.0817\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.4499 - accuracy: 0.1138 - val_loss: 2.7875 - val_accuracy: 0.0696\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4475 - accuracy: 0.1127 - val_loss: 2.7640 - val_accuracy: 0.0693\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4441 - accuracy: 0.1138 - val_loss: 2.7267 - val_accuracy: 0.0757\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4374 - accuracy: 0.1126 - val_loss: 2.7202 - val_accuracy: 0.0806\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4325 - accuracy: 0.1144 - val_loss: 2.7611 - val_accuracy: 0.0715\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4290 - accuracy: 0.1146 - val_loss: 2.7542 - val_accuracy: 0.0767\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4255 - accuracy: 0.1146 - val_loss: 2.7904 - val_accuracy: 0.0649\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4229 - accuracy: 0.1151 - val_loss: 2.7824 - val_accuracy: 0.0660\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 28s 179ms/step - loss: 2.4182 - accuracy: 0.1138 - val_loss: 2.7519 - val_accuracy: 0.0756\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4155 - accuracy: 0.1145 - val_loss: 2.7765 - val_accuracy: 0.0733\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4120 - accuracy: 0.1157 - val_loss: 2.8094 - val_accuracy: 0.0632\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4065 - accuracy: 0.1145 - val_loss: 2.7583 - val_accuracy: 0.0755\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.4029 - accuracy: 0.1137 - val_loss: 2.7863 - val_accuracy: 0.0706\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.4004 - accuracy: 0.1146 - val_loss: 2.7836 - val_accuracy: 0.0699\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3987 - accuracy: 0.1147 - val_loss: 2.7908 - val_accuracy: 0.0718\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3938 - accuracy: 0.1160 - val_loss: 2.7854 - val_accuracy: 0.0702\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3945 - accuracy: 0.1155 - val_loss: 2.7915 - val_accuracy: 0.0693\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3923 - accuracy: 0.1144 - val_loss: 2.8135 - val_accuracy: 0.0686\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3909 - accuracy: 0.1155 - val_loss: 2.7753 - val_accuracy: 0.0755\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.3846 - accuracy: 0.1157 - val_loss: 2.7840 - val_accuracy: 0.0823\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3807 - accuracy: 0.1161 - val_loss: 2.7897 - val_accuracy: 0.0667\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 28s 178ms/step - loss: 2.3781 - accuracy: 0.1158 - val_loss: 2.8276 - val_accuracy: 0.0685\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3751 - accuracy: 0.1163 - val_loss: 2.8098 - val_accuracy: 0.0714\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3724 - accuracy: 0.1165 - val_loss: 2.8143 - val_accuracy: 0.0702\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 28s 177ms/step - loss: 2.3716 - accuracy: 0.1163 - val_loss: 2.8616 - val_accuracy: 0.0597\n"
     ]
    }
   ],
   "source": [
    "avg_acc_train = []\n",
    "avg_acc_test = []\n",
    "model_loss_train = []\n",
    "model_loss_test = []\n",
    "\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "for combo in combinations:\n",
    "    cnn = cnn_model(epochs_input=combo[0], batch_size_input=combo[1], under_represented_weighting=weights)\n",
    "    model_output_train = cnn.predict(X_train)\n",
    "    model_output_test = cnn.predict(X_test)\n",
    "\n",
    "    avg_acc_train += [mbti_accuracy(y_train, model_output_train)[4]]\n",
    "    avg_acc_test += [mbti_accuracy(y_test, model_output_test)[4]]\n",
    "\n",
    "    \n",
    "    model_loss_train += [cce(y_train, model_output_train).numpy()]\n",
    "    model_loss_test += [cce(y_test, model_output_test).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>avg_acc_train</th>\n",
       "      <th>avg_acc_test</th>\n",
       "      <th>model_loss_train</th>\n",
       "      <th>model_loss_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>256</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>512</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>128</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>256</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>512</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>512</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch  avg_acc_train  avg_acc_test  model_loss_train  \\\n",
       "0     30    128             52            49                 3   \n",
       "1     30    256             54            51                 3   \n",
       "2     30    512             51            49                 3   \n",
       "3     40    128             53            50                 3   \n",
       "4     40    256             52            49                 3   \n",
       "5     40    512             54            51                 3   \n",
       "6     50    128             54            50                 3   \n",
       "7     50    256             53            50                 3   \n",
       "8     50    512             51            48                 3   \n",
       "\n",
       "   model_loss_test  \n",
       "0                3  \n",
       "1                3  \n",
       "2                3  \n",
       "3                3  \n",
       "4                3  \n",
       "5                3  \n",
       "6                3  \n",
       "7                3  \n",
       "8                3  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_results = pd.DataFrame(combinations, columns=['epoch', 'batch'])\n",
    "hyperparameter_results['avg_acc_train'] = avg_acc_train\n",
    "hyperparameter_results['avg_acc_test'] = avg_acc_test\n",
    "hyperparameter_results['model_loss_train'] = model_loss_train\n",
    "hyperparameter_results['model_loss_test'] = model_loss_test\n",
    "hyperparameter_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_results.to_csv('../NLP_MBTI_Classification/results_summary/cnn_hyperparameter_tuning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
